线性回归
Pytorch涉及的基本数据类型是tensor（张量）和Autograd（自动微分变量），对于这些概念我也是一知半解，tensor和向量，矩阵等概念都有交叉的部分，下次有时间好好补一下数学的基础知识，不过现阶段的任务主要是应用，学习掌握思维和方法即可，就不再深究了。tensor和ndarray可以相互转换，python的numpy库中的命令也都基本适用

线性关系是一种非常简单的变量之间的关系，因变量和自变量在线性关系的情况下，可以使用线性回归算法对一个或多个因变量和自变量间的线性关系进行建模，该模型的系数可以用最小二乘法进行求解。生活中的场景往往会比较复杂，需要考虑多元线性关系和非线性关系，用其他的回归分析方法求解。

Softmax与分类模型
对于多分类的问题，我们可以用softmax回归。逻辑回归使用的是sigmoid函数，将wx+b的值映射到(0, 1)的区间，输出的结果为样本标签等于1的概率值；而softmax回归采用的是softmax函数，将wx+b的值映射到[0, 1]的区间，输出的结果为一个向量，向量里的值为样本属于每个标签的概率值.

多层感知机
首先，深度前馈网络(deep feedforward network)，也叫做前馈神经网络(feedforward neural network)或者多层感知机(Multilayer Perceptron，MLP)，多层感知机(MLP)又叫人工神经网络(Artificial Neural Network，ANN)，是典型的深度学习模型。其次，我觉得多层神经网络是一个很广泛的概念，所有那些具有较多隐藏层/中间层的神经网络都可以成为多层神经网络，还有一个深度神经网络(DNN)的概念，我觉得它就是多层神经网络。最后，卷积神经网络(CNN)和循环神经网络(RNN)是两种对简单全连接神经网络的传播过程进行设计的特殊/专业神经网络，这两种神经网络以后学习到时会介绍，这里就不具体说明了。
所以，感知机模型如果中间有很多隐藏层的话，也就属于多层神经网络。
